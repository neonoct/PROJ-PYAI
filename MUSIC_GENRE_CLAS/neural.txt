Epoch 47/50
1000/1000 - 1s - 1ms/step - accuracy: 0.6114 - loss: 0.9827 - val_accuracy: 0.5716 - val_loss: 1.1047
Epoch 48/50
1000/1000 - 1s - 1ms/step - accuracy: 0.6125 - loss: 0.9823 - val_accuracy: 0.5686 - val_loss: 1.1109
Epoch 49/50
1000/1000 - 1s - 1ms/step - accuracy: 0.6131 - loss: 0.9818 - val_accuracy: 0.5700 - val_loss: 1.1078
Epoch 50/50
1000/1000 - 1s - 1ms/step - accuracy: 0.6128 - loss: 0.9803 - val_accuracy: 0.5587 - val_loss: 1.1250
313/313 - 0s - 2ms/step - accuracy: 0.5742 - loss: 1.0926
Test accuracy: 0.5741999745368958

Observations:
Accuracy: The training accuracy reached around 61%, and the validation accuracy is around 56-57%. This indicates some overfitting, where the model performs better on the training data than on the validation data.
Loss: The training loss and validation loss indicate that there is room for improvement in the model's generalization.

Enhanced Neural Network Model
Dropout Layers: To prevent overfitting.
Deeper Architecture: Adding more layers.
Activation Functions: Using relu and experimenting with others like leaky_relu if needed.
Batch Normalization: To stabilize and speed up the training.

Epoch 98/100
1000/1000 - 2s - 2ms/step - accuracy: 0.5300 - loss: 1.2456 - val_accuracy: 0.5617 - val_loss: 1.1089
Epoch 99/100
1000/1000 - 2s - 2ms/step - accuracy: 0.5363 - loss: 1.2440 - val_accuracy: 0.5684 - val_loss: 1.1092
Epoch 100/100
1000/1000 - 2s - 2ms/step - accuracy: 0.5354 - loss: 1.2449 - val_accuracy: 0.5726 - val_loss: 1.1040
313/313 - 1s - 2ms/step - accuracy: 0.5740 - loss: 1.0939
Test accuracy: 0.5740000009536743

The updated neural network has achieved a test accuracy of approximately 57.4%, which is consistent with the performance of the other models you've tried. The accuracy and loss plots indicate that the model is learning, with the validation accuracy stabilizing over epochs.

Observations:
Training and Validation Accuracy: Both training and validation accuracy are improving and stabilizing, which suggests the model is learning well without overfitting significantly.
Training and Validation Loss: Both training and validation loss are decreasing, indicating good convergence.

######################-newneural.py
#neural network after hyparparameter tuning
625/625 - 1s - 2ms/step - accuracy: 0.5776 - loss: 1.1020
Epoch 99/100
625/625 - 1s - 2ms/step - accuracy: 0.5778 - loss: 1.0958
Epoch 100/100
625/625 - 1s - 2ms/step - accuracy: 0.5769 - loss: 1.0971
Best parameters: {'model__optimizer': 'rmsprop', 'model__neurons': 128, 'model__dropout_rate': 0.3, 'epochs': 100, 'batch_size': 64}
Best cross-validation accuracy: 0.5901749688634972
157/157 - 0s - 3ms/step
Test accuracy of best model: 0.6007
              precision    recall  f1-score   support

           0       0.54      0.34      0.42      1008
           1       0.79      0.77      0.78      1034
           2       0.66      0.52      0.58      1021
           3       0.85      0.83      0.84       955
           4       0.54      0.60      0.57       986
           5       0.73      0.59      0.65      1009
           6       0.46      0.54      0.50       995
           7       0.53      0.59      0.56       985
           8       0.49      0.47      0.48      1030
           9       0.52      0.77      0.62       977

    accuracy                           0.60     10000
   macro avg       0.61      0.60      0.60     10000
weighted avg       0.61      0.60      0.60     10000

[[347  12  14   1 168  29 117  72  45 203]
 [ 20 801  54  51  51  28   0  22   0   7]
 [ 48  82 529  20 107  35   3 138   4  55]
 [ 23  45  25 788   5   5   0  62   0   2]
 [ 40  14  34   0 591  11  34  63  10 189]
 [ 51  46  70   7  56 597  19 124  16  23]
 [ 16   0   2   0   8  12 536  11 367  43]
 [ 32  14  75  55  66  89  21 585   1  47]
 [ 11   0   0   0   3   6 396   7 484 123]
 [ 58   6   3   2  41   4  33  26  55 749]]

 The neural network model has achieved a test accuracy of 60.07% after hyperparameter tuning. This is an improvement over previous models and suggests that the tuning process has been beneficial. The detailed classification report and confusion matrix provide further insights into the model's performance across different classes.

Key Metrics:
Best Parameters:
optimizer: 'rmsprop'
neurons: 128
dropout_rate: 0.3
epochs: 100
batch_size: 64
Best Cross-Validation Accuracy: 59.02%
Test Accuracy: 60.07%
Classification Report: Provides precision, recall, and F1-score for each class.
Confusion Matrix: Shows the number of correct and incorrect predictions for each class.

Observations:
Improvement: The model shows significant improvement with the optimized hyperparameters.
Class Imbalance: Some classes have better precision and recall than others, indicating potential issues with class imbalance.
Detailed Insights: The confusion matrix and classification report provide detailed insights into where the model is performing well and where it needs improvement.